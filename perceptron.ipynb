{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294b8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical AND:\n",
      "Inputs: [0 0 0], Ground Truth: 0, Output: 0.22468292191128916\n",
      "Inputs: [0 0 1], Ground Truth: 0, Output: 0.19923237226614324\n",
      "Inputs: [0 1 0], Ground Truth: 0, Output: 0.09822557382202989\n",
      "Inputs: [0 1 1], Ground Truth: 0, Output: 0.08551925538455032\n",
      "Inputs: [1 0 0], Ground Truth: 0, Output: 0.09740845356266684\n",
      "Inputs: [1 0 1], Ground Truth: 0, Output: 0.08479789703615737\n",
      "Inputs: [1 1 0], Ground Truth: 0, Output: 0.03898275384250722\n",
      "Inputs: [1 1 1], Ground Truth: 1, Output: 0.03365399870164499\n",
      "\n",
      "Logical OR:\n",
      "Inputs: [0 0 0], Ground Truth: 0, Output: 0.7320360656216722\n",
      "Inputs: [0 0 1], Ground Truth: 1, Output: 0.8222622789152123\n",
      "Inputs: [0 1 0], Ground Truth: 1, Output: 0.8336292326383951\n",
      "Inputs: [0 1 1], Ground Truth: 1, Output: 0.8945744345071638\n",
      "Inputs: [1 0 0], Ground Truth: 1, Output: 0.8512761925349132\n",
      "Inputs: [1 0 1], Ground Truth: 1, Output: 0.9064821260348357\n",
      "Inputs: [1 1 0], Ground Truth: 1, Output: 0.9130325959511355\n",
      "Inputs: [1 1 1], Ground Truth: 1, Output: 0.9467486884344587\n",
      "\n",
      "Logical XOR:\n",
      "Inputs: [0 0 0], Ground Truth: 0, Output: 0.463833554120917\n",
      "Inputs: [0 0 1], Ground Truth: 0, Output: 0.5650387840187386\n",
      "Inputs: [0 1 0], Ground Truth: 1, Output: 0.3934623409472559\n",
      "Inputs: [0 1 1], Ground Truth: 1, Output: 0.49344410676733974\n",
      "Inputs: [1 0 0], Ground Truth: 1, Output: 0.49097381420617914\n",
      "Inputs: [1 0 1], Ground Truth: 1, Output: 0.5915671581068275\n",
      "Inputs: [1 1 0], Ground Truth: 0, Output: 0.4197082307119327\n",
      "Inputs: [1 1 1], Ground Truth: 0, Output: 0.5206345575215543\n"
     ]
    }
   ],
   "source": [
    "# Percptron(Single Neuron)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.sigmoid(np.dot(x, self.weights) + self.bias)\n",
    "\n",
    "    def gradient_descent(self, x, y):\n",
    "        output = self.predict(x)\n",
    "        error = y - output\n",
    "        d_weights = np.dot(x.T, error * (output * (1 - output)))\n",
    "        d_bias = np.sum(error * (output * (1 - output)))\n",
    "        self.weights += self.learning_rate * d_weights\n",
    "        self.bias += self.learning_rate * d_bias\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for _ in range(self.epochs):\n",
    "            for x, label in zip(X, y):\n",
    "                self.gradient_descent(x, label)\n",
    "\n",
    "# Define logical functions\n",
    "def logical_and(x):\n",
    "    return int(all(x))\n",
    "\n",
    "def logical_or(x):\n",
    "    return int(any(x))\n",
    "\n",
    "def logical_xor(x):\n",
    "    return int((x[0] and not x[1]) or (not x[0] and x[1]))\n",
    "\n",
    "# Generate inputs for all combinations of 0 and 1 for x1, x2, x3\n",
    "inputs = np.array([[i, j, k] for i in range(2) for j in range(2) for k in range(2)])\n",
    "\n",
    "# Ground truth labels for logical functions\n",
    "ground_truth_and = np.array([logical_and(x) for x in inputs])\n",
    "ground_truth_or = np.array([logical_or(x) for x in inputs])\n",
    "ground_truth_xor = np.array([logical_xor(x) for x in inputs])\n",
    "\n",
    "# Initialize and train perceptrons for each logical function\n",
    "perceptron_and = Perceptron(input_size=3)\n",
    "perceptron_and.train(inputs, ground_truth_and)\n",
    "\n",
    "perceptron_or = Perceptron(input_size=3)\n",
    "perceptron_or.train(inputs, ground_truth_or)\n",
    "\n",
    "perceptron_xor = Perceptron(input_size=3)\n",
    "perceptron_xor.train(inputs, ground_truth_xor)\n",
    "\n",
    "# Print ground truth and outputs of trained perceptrons\n",
    "print(\"Logical AND:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_and[i]}, Output: {perceptron_and.predict(x)}\")\n",
    "\n",
    "print(\"\\nLogical OR:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_or[i]}, Output: {perceptron_or.predict(x)}\")\n",
    "\n",
    "print(\"\\nLogical XOR:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_xor[i]}, Output: {perceptron_xor.predict(x)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238295e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical AND:\n",
      "Inputs: [0 0 0], Ground Truth: [0], Output: [[0.14703811]]\n",
      "Inputs: [0 0 1], Ground Truth: [0], Output: [[0.08923531]]\n",
      "Inputs: [0 1 0], Ground Truth: [0], Output: [[0.10349994]]\n",
      "Inputs: [0 1 1], Ground Truth: [0], Output: [[0.06755765]]\n",
      "Inputs: [1 0 0], Ground Truth: [0], Output: [[0.12638466]]\n",
      "Inputs: [1 0 1], Ground Truth: [0], Output: [[0.08978483]]\n",
      "Inputs: [1 1 0], Ground Truth: [0], Output: [[0.08535347]]\n",
      "Inputs: [1 1 1], Ground Truth: [1], Output: [[0.06178064]]\n",
      "\n",
      "Logical OR:\n",
      "Inputs: [0 0 0], Ground Truth: [0], Output: [[0.81586451]]\n",
      "Inputs: [0 0 1], Ground Truth: [1], Output: [[0.8774782]]\n",
      "Inputs: [0 1 0], Ground Truth: [1], Output: [[0.8614023]]\n",
      "Inputs: [0 1 1], Ground Truth: [1], Output: [[0.90653534]]\n",
      "Inputs: [1 0 0], Ground Truth: [1], Output: [[0.84092208]]\n",
      "Inputs: [1 0 1], Ground Truth: [1], Output: [[0.84948168]]\n",
      "Inputs: [1 1 0], Ground Truth: [1], Output: [[0.86808082]]\n",
      "Inputs: [1 1 1], Ground Truth: [1], Output: [[0.87189569]]\n",
      "\n",
      "Logical XOR:\n",
      "Inputs: [0 0 0], Ground Truth: [0], Output: [[0.77595151]]\n",
      "Inputs: [0 0 1], Ground Truth: [1], Output: [[0.79530815]]\n",
      "Inputs: [0 1 0], Ground Truth: [1], Output: [[0.73544733]]\n",
      "Inputs: [0 1 1], Ground Truth: [1], Output: [[0.76998174]]\n",
      "Inputs: [1 0 0], Ground Truth: [1], Output: [[0.72368495]]\n",
      "Inputs: [1 0 1], Ground Truth: [1], Output: [[0.7619392]]\n",
      "Inputs: [1 1 0], Ground Truth: [0], Output: [[0.69481491]]\n",
      "Inputs: [1 1 1], Ground Truth: [1], Output: [[0.74591625]]\n"
     ]
    }
   ],
   "source": [
    "# Multi-Layer Perceptron\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01, epochs=1000):\n",
    "        self.hidden_weights = np.random.randn(input_size, hidden_size)\n",
    "        self.hidden_bias = np.random.randn(hidden_size)\n",
    "        self.output_weights = np.random.randn(hidden_size, output_size)\n",
    "        self.output_bias = np.random.randn(output_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        hidden_layer_output = self.sigmoid(np.dot(x, self.hidden_weights) + self.hidden_bias)\n",
    "        output_layer_output = self.sigmoid(np.dot(hidden_layer_output, self.output_weights) + self.output_bias)\n",
    "        return output_layer_output\n",
    "\n",
    "    def gradient_descent(self, x, y):\n",
    "        hidden_layer_output = self.sigmoid(np.dot(x, self.hidden_weights) + self.hidden_bias)\n",
    "        output_layer_output = self.sigmoid(np.dot(hidden_layer_output, self.output_weights) + self.output_bias)\n",
    "\n",
    "        output_error = y - output_layer_output\n",
    "        output_delta = output_error * output_layer_output * (1 - output_layer_output)\n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.output_weights.T)\n",
    "        hidden_delta = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n",
    "\n",
    "        self.output_weights += self.learning_rate * np.dot(hidden_layer_output.T, output_delta)\n",
    "        self.output_bias += self.learning_rate * np.sum(output_delta, axis=0)\n",
    "\n",
    "        self.hidden_weights += self.learning_rate * np.dot(x.T, hidden_delta)\n",
    "        self.hidden_bias += self.learning_rate * np.sum(hidden_delta, axis=0)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for _ in range(self.epochs):\n",
    "            for x, label in zip(X, y):\n",
    "                x = x[np.newaxis, :]  # Convert input to 2D array\n",
    "                label = label[np.newaxis, :]  # Convert label to 2D array\n",
    "                self.gradient_descent(x, label)\n",
    "\n",
    "# Define logical functions\n",
    "def logical_and(x):\n",
    "    return np.array([int(all(row)) for row in x])\n",
    "\n",
    "def logical_or(x):\n",
    "    return np.array([int(any(row)) for row in x])\n",
    "\n",
    "def logical_xor(x):\n",
    "    return np.array([int((row[0] and not row[1]) or (not row[0] and row[1]) or row[2]) for row in x])\n",
    "\n",
    "# Generate inputs for all combinations of 0 and 1 for x1, x2, x3\n",
    "inputs = np.array([[i, j, k] for i in range(2) for j in range(2) for k in range(2)])\n",
    "\n",
    "# Ground truth labels for logical functions\n",
    "ground_truth_and = logical_and(inputs)[:, np.newaxis]\n",
    "ground_truth_or = logical_or(inputs)[:, np.newaxis]\n",
    "ground_truth_xor = logical_xor(inputs)[:, np.newaxis]\n",
    "\n",
    "# Initialize and train MLPs for each logical function\n",
    "mlp_and = MLP(input_size=3, hidden_size=5, output_size=1)\n",
    "mlp_and.train(inputs, ground_truth_and)\n",
    "\n",
    "mlp_or = MLP(input_size=3, hidden_size=5, output_size=1)\n",
    "mlp_or.train(inputs, ground_truth_or)\n",
    "\n",
    "mlp_xor = MLP(input_size=3, hidden_size=5, output_size=1)\n",
    "mlp_xor.train(inputs, ground_truth_xor)\n",
    "\n",
    "# Print ground truth and outputs of trained MLPs\n",
    "print(\"Logical AND:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_and[i]}, Output: {mlp_and.predict(x[np.newaxis, :])}\")\n",
    "\n",
    "print(\"\\nLogical OR:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_or[i]}, Output: {mlp_or.predict(x[np.newaxis, :])}\")\n",
    "\n",
    "print(\"\\nLogical XOR:\")\n",
    "for i, x in enumerate(inputs):\n",
    "    print(f\"Inputs: {x}, Ground Truth: {ground_truth_xor[i]}, Output: {mlp_xor.predict(x[np.newaxis, :])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
